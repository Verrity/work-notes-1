
---
### Теги

### [[Home|Назад]]
### Далее
####
---

### Многопоточность
#### Lockfree очередь
Строится на простых атомарных операциях, предоставляет неблокирующую очередь. 
(Усугубляет инвалидацию кэша. **Проблема**: В lock-free очереди все потоки дергают одни и те же атомарные переменные (head, tail, счетчики). Каждый CAS — это принудительная инвалидация кэшей всех других ядер.)
#### work-stealing очередь
(решает инвалидацию кэша.)
У кажого воркера есть своя очередь. Если у одного воркера нет работы, он может украсть задачу из очереди другого воркера.

#### Инвалидация кэша
Представьте, что у каждого ядра процессора есть **своя быстрая память (кэш L1/L2)**. Когда поток читает данные из оперативной памяти, они копируются в кэш его ядра. При повторном доступе — данные берутся из быстрого кэша, а не из медленной RAM.
**Инвалидация кэша** — это принудительное объявление данных в кэше другого ядра **недействительными**, когда какое-то ядро изменяет эти данные.
**Как это происходит на примере мьютекса**
```cpp unfold
// Все потоки дергают этот мьютекс
std::mutex global_mutex;
int shared_counter = 0;

void worker() {
    std::lock_guard<std::mutex> lock(global_mutex);
    shared_counter++;  // КАТАСТРОФА для кэшей!
}
```
Шаги при работе 4 потоков:
```text unfold
Время 0: 
Ядро 1: мьютекс в кэше (состояние: unlocked)
Ядро 2: мьютекс в кэше (состояние: unlocked) 
Ядро 3: мьютекс в кэше (состояние: unlocked)

Время 1: Поток на ядре 1 lock():
1. Проверяет мьютекс в своем кэше → unlocked
2. Меняет на locked → записывает в свой кэш
3. Система должна сообщить всем: "Ваши копии устарели!"

Время 2: Протокол MESI срабатывает:
Ядро 1: мьютекс в состоянии Modified (M)
Ядро 2: инвалидирует свою копию → состояние Invalid (I)
Ядро 3: инвалидирует свою копию → состояние Invalid (I)

Время 3: Поток на ядре 2 пытается lock():
1. Смотрит в кэш → состояние Invalid
2. Вынужден запросить у ядра 1: "Дай свежую копию!"
3. Ядро 1 сбрасывает данные в общую память
4. Ядро 2 читает из памяти → 100+ тактов задержки!
```



## **1. КЭШ ЯДРА**
- Каждое ядро процессора имеет собственную сверхбыструю память на чипе
- Уровни: L1 (самый быстрый, ~1-2 нс, 32-64 КБ), L2 (~5-10 нс, 256-512 КБ), L3 (общий, ~20-30 нс, 16-64 МБ)
- Кэш работает **строками по 64 байта** (cache line)
- При доступе к памяти загружается ВСЯ строка 64 байта, даже если нужен 1 байт

## **2. ИНВАЛИДАЦИЯ КЭША**
- В многопроцессорной системе у каждого ядра своя копия данных в кэше
- При изменении данных одним ядром система помечает копии этих данных в кэшах других ядер как **недействительные**
- Другие ядра при следующем доступе вынуждены загружать свежие данные из памяти или из кэша ядра-изменителя
- **Задержка**: Переход из состояния "кэш есть" (1-5 нс) в "нужно загружать из RAM" (80-120 нс)

**Механизм MESI (протокол когерентности кэшей):**
- **M**odified (изменён) — данные изменены только в этом кэше
- **E**xclusive (эксклюзив) — данные есть только в этом кэше, не изменены
- **S**hared (разделяемый) — данные есть в нескольких кэшах, не изменены
- **I**nvalid (недействительный) — данные устарели
Переход из S → I при записи другим ядром = инвалидация.

## **3. FALSE SHARING**
- Возникает, когда несвязанные данные разных потоков попадают в одну cache-line (64 байта)
- Поток A работает с переменной X, поток B с переменной Y
- X и Y случайно оказались в одной cache-line
- Поток A записывает X → вся cache-line помечается изменённой
- Кэш потока B инвалидируется, хотя его переменная Y не изменялась
- Поток B при доступе к Y получает принудительную перезагрузку данных    

**Пример:**
```cpp unfold
// ПЛОХО: false sharing
struct Data {
    int x; // Поток 1 работает тут
    int y; // Поток 2 работает тут
    // x и y в одной cache-line!
};

// ХОРОШО: разделено
struct Data {
    alignas(64) int x; // Выровнено по границе cache-line
    alignas(64) int y; // В разных cache-line
};
```

## **4. БАРЬЕР ПАМЯТИ (MEMORY BARRIER/FENCE)**
- Процессор и компилятор переупорядочивают операции с памятью для оптимизации
- Барьер памяти гарантирует, что все операции до барьера завершены до операций после барьера

**Типы барьеров:**
- **Load-load**: Чтение A завершено до чтения B
- **Store-store**: Запись A завершена до записи B
- **Load-store**: Чтение A завершено до записи B
- **Store-load**: Запись A завершено до чтения B (самый строгий)

**Пример проблемы без барьера:**
```cpp
// Поток 1        // Поток 2
data = 42;        while (!ready);
ready = true;     print(data);
```
Без барьера процессор может выполнить `ready = true` ДО `data = 42` → поток 2 увидит старые данные.

## **5. ATOMIC ОПЕРАЦИИ**

### **ОБЫЧНАЯ ЗАПИСЬ**
- Неатомарная операция
- Может прерываться, другие потоки видят промежуточные состояния
- Нет гарантий видимости для других ядер
- 1-3 такта процессора

### **ATOMIC LOAD**
- Атомарное чтение
- Гарантирует чтение целого значения (не частично записанного)
- Включает барьер памяти (зависит от memory_order)
- 10-20 тактов

### **ATOMIC CAS (COMPARE-AND-SWAP)**
```cpp unfold
bool compare_exchange_weak(T& expected, T desired) {
    if (*ptr == expected) {
        *ptr = desired;
        return true;
    } else {
        expected = *ptr;
        return false;
    }
}
```

- Атомарно: читает значение, сравнивает, при совпадении записывает новое
- Фундаментальная операция для lock-free алгоритмов
- Всегда включает полный memory barrier
- 30-100+ тактов в зависимости от contention

## **6. РАЗНИЦА CPU-BOUND vs I/O-BOUND**

### **CPU-BOUND (ОГРАНИЧЕНО ПРОЦЕССОРОМ)**

- Большую часть времени тратится на вычисления в процессоре
- Примеры: шифрование, сжатие, математические расчёты, рендеринг
- **Характеристики**:
    - Загрузка CPU ~100%
    - Мало операций ввода/вывода
    - Чувствительно к скорости процессора, кэшу, памяти
    - Параллелизм даёт линейное ускорение (до определённого предела)

### **I/O-BOUND (ОГРАНИЧЕНО ВВОДОМ/ВЫВОДОМ)**

- Большую часть времени тратится на ожидание операций ввода/вывода
- Примеры: скачивание файлов, чтение с диска, сетевые запросы, ожидание пользователя
- **Характеристики**:
    - Загрузка CPU низкая (потоки спят в ожидании)
    - Много операций ожидания
    - Не чувствительно к скорости процессора
    - Параллелизм не всегда даёт ускорение (упирается в bandwidth I/O)